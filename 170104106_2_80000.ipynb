{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "170104106_2_80000.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGNYpKArN4AA"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import mean\n",
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zec8nz2jOOaW",
        "outputId": "bf748845-f2e3-44ca-d967-5ec3366290a6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = 'drive/My Drive/SoftCom/training-a'\n",
        "a_csv = pd.read_csv('drive/My Drive/SoftCom/training-a.csv',low_memory=False)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "sRkVoZf9Oz4C",
        "outputId": "62be1360-d186-47ba-c874-c34433f92e2c"
      },
      "source": [
        "#a_csv = pd.read_csv('/content/drive/MyDrive/SoftCom/training-a.csv')\n",
        "a_csv.columns\n",
        "a_csv = a_csv.drop(columns=['original filename', 'scanid',\n",
        "       'database name original', 'contributing team', 'database name'])\n",
        "a_csv.iloc[:10, 0:]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a00000.png</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a00001.png</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a00002.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a00003.png</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a00004.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>a00005.png</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>a00006.png</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>a00007.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>a00008.png</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>a00009.png</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     filename  digit\n",
              "0  a00000.png      5\n",
              "1  a00001.png      3\n",
              "2  a00002.png      1\n",
              "3  a00003.png      7\n",
              "4  a00004.png      0\n",
              "5  a00005.png      4\n",
              "6  a00006.png      3\n",
              "7  a00007.png      0\n",
              "8  a00008.png      4\n",
              "9  a00009.png      9"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIk1y6hjPEdX"
      },
      "source": [
        "label_csv = a_csv"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJs815VFPGVk"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(self, df, root, transform=None):\n",
        "        self.data = df\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        item = self.data.iloc[index]\n",
        "        \n",
        "        path = self.root + \"/\" + item[0]\n",
        "        image = Image.open(path).convert('L')\n",
        "        label = item[1]\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        return image, label"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6y58ppUhPbgY",
        "outputId": "69502f4f-134d-48d6-ca62-20d42ec67113"
      },
      "source": [
        "mean = [0.5,]\n",
        "std = [0.5, ]\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(180),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "        transforms.Resize(180),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "train_data  = Dataset(label_csv, path, train_transform)\n",
        "test_data = Dataset(label_csv, path, test_transform)\n",
        "\n",
        "print(\"Trainig Samples: \",len(train_data))\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainig Samples:  19702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH5tPxyMPf1g"
      },
      "source": [
        "batch_size = 20\n",
        "num_iters = 80000\n",
        "input_dim = 180*180 \n",
        "num_hidden = 200  \n",
        "output_dim = 10\n",
        "num_epochs = num_iters / (len(train_data) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "learning_rate = 0.01  # More power so we can learn faster! previously it was 0.001\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_data, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)   # It's better to shuffle the whole training dataset! \n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_data, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)  "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5qew4NRPiXS",
        "outputId": "ac66d2dc-f95d-4ada-cbd8-9b8a21e8fd32"
      },
      "source": [
        "import torch.nn as nn\n",
        "class DeepNeuralNetworkModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "       \n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
        "        \n",
        "        self.relu_1 = nn.ReLU()\n",
        " \n",
        "        \n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
        "        \n",
        "        self.relu_2 = nn.ReLU()\n",
        " \n",
        "        \n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
        "        \n",
        "        self.relu_3 = nn.ReLU()\n",
        " \n",
        "         \n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
        "        \n",
        "        self.relu_4 = nn.ReLU()\n",
        " \n",
        "         \n",
        "        self.linear_5= nn.Linear(num_hidden, num_hidden)\n",
        "        \n",
        "        self.relu_5= nn.ReLU()\n",
        " \n",
        "         \n",
        "        self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
        "        \n",
        "        self.relu_6 = nn.ReLU()\n",
        " \n",
        "        \n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
        " \n",
        "    def forward(self, x):\n",
        "        ### 1st hidden layer\n",
        "        out  = self.linear_1(x)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        out = self.relu_1(out)\n",
        "        \n",
        "        ### 2nd hidden layer\n",
        "        out  = self.linear_2(out)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        out = self.relu_2(out)\n",
        " \n",
        "        ### 3rd hidden layer\n",
        "        out  = self.linear_3(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_3(out)\n",
        " \n",
        "        out  = self.linear_4(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_4(out)\n",
        " \n",
        "        out  = self.linear_5(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_5(out)\n",
        " \n",
        "        out  = self.linear_6(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_6(out)\n",
        "        \n",
        "        # Linear layer (output)\n",
        "        probas  = self.linear_out(out)\n",
        "        return probas\n",
        " \n",
        "# INSTANTIATE MODEL CLASS\n",
        " \n",
        "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
        "                               num_classes = output_dim,\n",
        "                               num_hidden = num_hidden)\n",
        "# To enable GPU\n",
        "model.to(device)\n",
        " \n",
        "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        " \n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        " \n",
        "        images = images.view(-1, 180*180).to(device)\n",
        "        labels = labels.to(device)\n",
        " \n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        " \n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images) \n",
        " \n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        " \n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        " \n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        " \n",
        "        iter += 1\n",
        " \n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "               \n",
        "                images = images.view(-1, 180*180).to(device)\n",
        " \n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        " \n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        " \n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        " \n",
        " \n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        " \n",
        "            accuracy = 100 * correct.item() / total\n",
        " \n",
        "            # Print Loss\n",
        "            print('Iteration: {}. \\n Loss: {}.\\n  Accuracy: {}\\n'.format(iter, loss.item(), accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 500. \n",
            " Loss: 2.3059258460998535.\n",
            "  Accuracy: 10.070043650390824\n",
            "\n",
            "Iteration: 1000. \n",
            " Loss: 2.3030574321746826.\n",
            "  Accuracy: 9.968531113592528\n",
            "\n",
            "Iteration: 1500. \n",
            " Loss: 2.3017992973327637.\n",
            "  Accuracy: 10.070043650390824\n",
            "\n",
            "Iteration: 2000. \n",
            " Loss: 2.2963738441467285.\n",
            "  Accuracy: 9.973606740432443\n",
            "\n",
            "Iteration: 2500. \n",
            " Loss: 2.295295000076294.\n",
            "  Accuracy: 9.963455486752615\n",
            "\n",
            "Iteration: 3000. \n",
            " Loss: 2.2889914512634277.\n",
            "  Accuracy: 10.070043650390824\n",
            "\n",
            "Iteration: 3500. \n",
            " Loss: 2.29666805267334.\n",
            "  Accuracy: 10.070043650390824\n",
            "\n",
            "Iteration: 4000. \n",
            " Loss: 2.234300136566162.\n",
            "  Accuracy: 10.02436300883159\n",
            "\n",
            "Iteration: 4500. \n",
            " Loss: 2.157413959503174.\n",
            "  Accuracy: 10.075119277230739\n",
            "\n",
            "Iteration: 5000. \n",
            " Loss: 2.115894079208374.\n",
            "  Accuracy: 10.349203126586133\n",
            "\n",
            "Iteration: 5500. \n",
            " Loss: 1.912954568862915.\n",
            "  Accuracy: 14.095015734443203\n",
            "\n",
            "Iteration: 6000. \n",
            " Loss: 2.0489957332611084.\n",
            "  Accuracy: 10.009136128311846\n",
            "\n",
            "Iteration: 6500. \n",
            " Loss: 1.899873971939087.\n",
            "  Accuracy: 9.877169830474063\n",
            "\n",
            "Iteration: 7000. \n",
            " Loss: 1.8441193103790283.\n",
            "  Accuracy: 9.983757994112272\n",
            "\n",
            "Iteration: 7500. \n",
            " Loss: 2.0785720348358154.\n",
            "  Accuracy: 9.968531113592528\n",
            "\n",
            "Iteration: 8000. \n",
            " Loss: 2.126140832901001.\n",
            "  Accuracy: 9.927926098873211\n",
            "\n",
            "Iteration: 8500. \n",
            " Loss: 1.9526989459991455.\n",
            "  Accuracy: 10.004060501471931\n",
            "\n",
            "Iteration: 9000. \n",
            " Loss: 2.0550200939178467.\n",
            "  Accuracy: 12.11552126687646\n",
            "\n",
            "Iteration: 9500. \n",
            " Loss: 1.7276859283447266.\n",
            "  Accuracy: 16.91198863059588\n",
            "\n",
            "Iteration: 10000. \n",
            " Loss: 2.075968027114868.\n",
            "  Accuracy: 13.0595878591006\n",
            "\n",
            "Iteration: 10500. \n",
            " Loss: 1.6362148523330688.\n",
            "  Accuracy: 9.943152979392956\n",
            "\n",
            "Iteration: 11000. \n",
            " Loss: 1.8999007940292358.\n",
            "  Accuracy: 10.075119277230739\n",
            "\n",
            "Iteration: 11500. \n",
            " Loss: 1.9823449850082397.\n",
            "  Accuracy: 11.917571820119784\n",
            "\n",
            "Iteration: 12000. \n",
            " Loss: 2.0084683895111084.\n",
            "  Accuracy: 11.623185463404731\n",
            "\n",
            "Iteration: 12500. \n",
            " Loss: 1.9697258472442627.\n",
            "  Accuracy: 16.08973708252969\n",
            "\n",
            "Iteration: 13000. \n",
            " Loss: 1.7616450786590576.\n",
            "  Accuracy: 12.846411531824181\n",
            "\n",
            "Iteration: 13500. \n",
            " Loss: 1.8668901920318604.\n",
            "  Accuracy: 12.66368896558725\n",
            "\n",
            "Iteration: 14000. \n",
            " Loss: 1.8507789373397827.\n",
            "  Accuracy: 14.440158359557405\n",
            "\n",
            "Iteration: 14500. \n",
            " Loss: 1.8396055698394775.\n",
            "  Accuracy: 14.80052786519135\n",
            "\n",
            "Iteration: 15000. \n",
            " Loss: 1.8578351736068726.\n",
            "  Accuracy: 11.82621053700132\n",
            "\n",
            "Iteration: 15500. \n",
            " Loss: 1.784930944442749.\n",
            "  Accuracy: 11.044564003654452\n",
            "\n",
            "Iteration: 16000. \n",
            " Loss: 1.6771466732025146.\n",
            "  Accuracy: 11.724698000203025\n",
            "\n",
            "Iteration: 16500. \n",
            " Loss: 1.7854076623916626.\n",
            "  Accuracy: 18.206273474774136\n",
            "\n",
            "Iteration: 17000. \n",
            " Loss: 1.5682578086853027.\n",
            "  Accuracy: 16.145568977768754\n",
            "\n",
            "Iteration: 17500. \n",
            " Loss: 1.7462174892425537.\n",
            "  Accuracy: 13.485940513653436\n",
            "\n",
            "Iteration: 18000. \n",
            " Loss: 1.6648536920547485.\n",
            "  Accuracy: 18.48035732412953\n",
            "\n",
            "Iteration: 18500. \n",
            " Loss: 1.6628364324569702.\n",
            "  Accuracy: 15.125367982945894\n",
            "\n",
            "Iteration: 19000. \n",
            " Loss: 1.6456985473632812.\n",
            "  Accuracy: 21.348086488681354\n",
            "\n",
            "Iteration: 19500. \n",
            " Loss: 1.7308218479156494.\n",
            "  Accuracy: 16.272459648766624\n",
            "\n",
            "Iteration: 20000. \n",
            " Loss: 1.4397010803222656.\n",
            "  Accuracy: 24.408689473149934\n",
            "\n",
            "Iteration: 20500. \n",
            " Loss: 1.9297386407852173.\n",
            "  Accuracy: 24.18028626535377\n",
            "\n",
            "Iteration: 21000. \n",
            " Loss: 1.6995480060577393.\n",
            "  Accuracy: 22.91137955537509\n",
            "\n",
            "Iteration: 21500. \n",
            " Loss: 1.470726728439331.\n",
            "  Accuracy: 26.301898284438128\n",
            "\n",
            "Iteration: 22000. \n",
            " Loss: 1.798291802406311.\n",
            "  Accuracy: 25.043142828139274\n",
            "\n",
            "Iteration: 22500. \n",
            " Loss: 2.098206043243408.\n",
            "  Accuracy: 22.89107704801543\n",
            "\n",
            "Iteration: 23000. \n",
            " Loss: 1.337488055229187.\n",
            "  Accuracy: 23.550908537204343\n",
            "\n",
            "Iteration: 23500. \n",
            " Loss: 1.8948131799697876.\n",
            "  Accuracy: 30.474063546848036\n",
            "\n",
            "Iteration: 24000. \n",
            " Loss: 1.586815595626831.\n",
            "  Accuracy: 24.753832098264137\n",
            "\n",
            "Iteration: 24500. \n",
            " Loss: 2.049661159515381.\n",
            "  Accuracy: 21.373464622880928\n",
            "\n",
            "Iteration: 25000. \n",
            " Loss: 1.3881229162216187.\n",
            "  Accuracy: 22.896152674855344\n",
            "\n",
            "Iteration: 25500. \n",
            " Loss: 1.7514219284057617.\n",
            "  Accuracy: 20.622271850573547\n",
            "\n",
            "Iteration: 26000. \n",
            " Loss: 1.3624396324157715.\n",
            "  Accuracy: 23.647345447162724\n",
            "\n",
            "Iteration: 26500. \n",
            " Loss: 1.5774776935577393.\n",
            "  Accuracy: 26.276520150238554\n",
            "\n",
            "Iteration: 27000. \n",
            " Loss: 1.674432396888733.\n",
            "  Accuracy: 13.364125469495482\n",
            "\n",
            "Iteration: 27500. \n",
            " Loss: 1.569319248199463.\n",
            "  Accuracy: 19.662978377829663\n",
            "\n",
            "Iteration: 28000. \n",
            " Loss: 1.627307653427124.\n",
            "  Accuracy: 28.377829661963254\n",
            "\n",
            "Iteration: 28500. \n",
            " Loss: 1.4118200540542603.\n",
            "  Accuracy: 27.43376306973911\n",
            "\n",
            "Iteration: 29000. \n",
            " Loss: 1.6709916591644287.\n",
            "  Accuracy: 25.591310526850066\n",
            "\n",
            "Iteration: 29500. \n",
            " Loss: 1.763286828994751.\n",
            "  Accuracy: 31.468886407471324\n",
            "\n",
            "Iteration: 30000. \n",
            " Loss: 1.4380345344543457.\n",
            "  Accuracy: 34.219876154705105\n",
            "\n",
            "Iteration: 30500. \n",
            " Loss: 1.857330083847046.\n",
            "  Accuracy: 27.266267384021926\n",
            "\n",
            "Iteration: 31000. \n",
            " Loss: 1.4398431777954102.\n",
            "  Accuracy: 30.301492234290937\n",
            "\n",
            "Iteration: 31500. \n",
            " Loss: 1.3410863876342773.\n",
            "  Accuracy: 32.09826413562075\n",
            "\n",
            "Iteration: 32000. \n",
            " Loss: 1.2625683546066284.\n",
            "  Accuracy: 24.626941427266267\n",
            "\n",
            "Iteration: 32500. \n",
            " Loss: 1.1026737689971924.\n",
            "  Accuracy: 25.215714140696377\n",
            "\n",
            "Iteration: 33000. \n",
            " Loss: 1.0263620615005493.\n",
            "  Accuracy: 24.068622474875646\n",
            "\n",
            "Iteration: 33500. \n",
            " Loss: 1.04140305519104.\n",
            "  Accuracy: 30.580651710486244\n",
            "\n",
            "Iteration: 34000. \n",
            " Loss: 1.3074193000793457.\n",
            "  Accuracy: 35.676581057760636\n",
            "\n",
            "Iteration: 34500. \n",
            " Loss: 1.2811000347137451.\n",
            "  Accuracy: 27.413460562379456\n",
            "\n",
            "Iteration: 35000. \n",
            " Loss: 1.9518038034439087.\n",
            "  Accuracy: 31.717592122627146\n",
            "\n",
            "Iteration: 35500. \n",
            " Loss: 1.385406494140625.\n",
            "  Accuracy: 21.962237336311034\n",
            "\n",
            "Iteration: 36000. \n",
            " Loss: 2.5074620246887207.\n",
            "  Accuracy: 33.560044665516195\n",
            "\n",
            "Iteration: 36500. \n",
            " Loss: 1.437673807144165.\n",
            "  Accuracy: 31.118668155517206\n",
            "\n",
            "Iteration: 37000. \n",
            " Loss: 1.507749080657959.\n",
            "  Accuracy: 23.63211856664298\n",
            "\n",
            "Iteration: 37500. \n",
            " Loss: 1.5681473016738892.\n",
            "  Accuracy: 29.48939193990458\n",
            "\n",
            "Iteration: 38000. \n",
            " Loss: 1.6775891780853271.\n",
            "  Accuracy: 27.682468784894933\n",
            "\n",
            "Iteration: 38500. \n",
            " Loss: 1.3560835123062134.\n",
            "  Accuracy: 38.782864683788446\n",
            "\n",
            "Iteration: 39000. \n",
            " Loss: 1.271071434020996.\n",
            "  Accuracy: 31.900314688864075\n",
            "\n",
            "Iteration: 39500. \n",
            " Loss: 1.181436538696289.\n",
            "  Accuracy: 35.91513551923663\n",
            "\n",
            "Iteration: 40000. \n",
            " Loss: 1.113816499710083.\n",
            "  Accuracy: 39.17368795046188\n",
            "\n",
            "Iteration: 40500. \n",
            " Loss: 1.5786168575286865.\n",
            "  Accuracy: 29.839610191858693\n",
            "\n",
            "Iteration: 41000. \n",
            " Loss: 1.1273128986358643.\n",
            "  Accuracy: 35.417724088924984\n",
            "\n",
            "Iteration: 41500. \n",
            " Loss: 1.360753059387207.\n",
            "  Accuracy: 26.09887321084154\n",
            "\n",
            "Iteration: 42000. \n",
            " Loss: 1.5322825908660889.\n",
            "  Accuracy: 28.190031468886406\n",
            "\n",
            "Iteration: 42500. \n",
            " Loss: 1.445076823234558.\n",
            "  Accuracy: 36.696782052583494\n",
            "\n",
            "Iteration: 43000. \n",
            " Loss: 1.1437633037567139.\n",
            "  Accuracy: 37.290630392853515\n",
            "\n",
            "Iteration: 43500. \n",
            " Loss: 1.0952409505844116.\n",
            "  Accuracy: 39.02141914526444\n",
            "\n",
            "Iteration: 44000. \n",
            " Loss: 0.7556166648864746.\n",
            "  Accuracy: 34.6665313166176\n",
            "\n",
            "Iteration: 44500. \n",
            " Loss: 1.0419342517852783.\n",
            "  Accuracy: 37.45305045173079\n",
            "\n",
            "Iteration: 45000. \n",
            " Loss: 1.4206064939498901.\n",
            "  Accuracy: 34.53456501877982\n",
            "\n",
            "Iteration: 45500. \n",
            " Loss: 1.4174007177352905.\n",
            "  Accuracy: 37.255101004974115\n",
            "\n",
            "Iteration: 46000. \n",
            " Loss: 1.8266639709472656.\n",
            "  Accuracy: 40.112678915846104\n",
            "\n",
            "Iteration: 46500. \n",
            " Loss: 1.5075547695159912.\n",
            "  Accuracy: 26.890670997868238\n",
            "\n",
            "Iteration: 47000. \n",
            " Loss: 1.2790963649749756.\n",
            "  Accuracy: 39.671099380773526\n",
            "\n",
            "Iteration: 47500. \n",
            " Loss: 1.1440588235855103.\n",
            "  Accuracy: 36.02679930971475\n",
            "\n",
            "Iteration: 48000. \n",
            " Loss: 1.4540587663650513.\n",
            "  Accuracy: 33.96609481270937\n",
            "\n",
            "Iteration: 48500. \n",
            " Loss: 1.6438400745391846.\n",
            "  Accuracy: 36.31611003958989\n",
            "\n",
            "Iteration: 49000. \n",
            " Loss: 1.1640092134475708.\n",
            "  Accuracy: 34.61069942137854\n",
            "\n",
            "Iteration: 49500. \n",
            " Loss: 1.0715885162353516.\n",
            "  Accuracy: 26.469393970155313\n",
            "\n",
            "Iteration: 50000. \n",
            " Loss: 1.3950440883636475.\n",
            "  Accuracy: 34.483808750380675\n",
            "\n",
            "Iteration: 50500. \n",
            " Loss: 1.1451541185379028.\n",
            "  Accuracy: 40.44259466044056\n",
            "\n",
            "Iteration: 51000. \n",
            " Loss: 1.3068463802337646.\n",
            "  Accuracy: 37.16373972185565\n",
            "\n",
            "Iteration: 51500. \n",
            " Loss: 1.1762111186981201.\n",
            "  Accuracy: 33.30118769668054\n",
            "\n",
            "Iteration: 52000. \n",
            " Loss: 0.7279043197631836.\n",
            "  Accuracy: 41.96528271241498\n",
            "\n",
            "Iteration: 52500. \n",
            " Loss: 1.269844889640808.\n",
            "  Accuracy: 39.49852806821642\n",
            "\n",
            "Iteration: 53000. \n",
            " Loss: 1.3129650354385376.\n",
            "  Accuracy: 41.99573647345447\n",
            "\n",
            "Iteration: 53500. \n",
            " Loss: 1.1055809259414673.\n",
            "  Accuracy: 33.600649680235506\n",
            "\n",
            "Iteration: 54000. \n",
            " Loss: 1.0909911394119263.\n",
            "  Accuracy: 45.36595269515785\n",
            "\n",
            "Iteration: 54500. \n",
            " Loss: 0.8586708903312683.\n",
            "  Accuracy: 41.41203938686428\n",
            "\n",
            "Iteration: 55000. \n",
            " Loss: 1.3036572933197021.\n",
            "  Accuracy: 42.437316008527056\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9nBMWDtPs0h"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print (iteration_loss)\n",
        "plt.plot(iteration_loss)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Iteration')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}