{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "170104106_Assignment2_Part2_60000.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aTo6FyigWBx"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy import mean\n",
        "import torch\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIN4jxPIgnpI",
        "outputId": "5a4662c5-eae9-48a0-9443-c6f84d950c0f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = 'drive/My Drive/SoftCom/training-a'\n",
        "a_csv = pd.read_csv('drive/My Drive/SoftCom/training-a.csv',low_memory=False)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "ot6iGypugvCN",
        "outputId": "3e530c72-7118-4de6-99cf-74e5518e4670"
      },
      "source": [
        "#a_csv = pd.read_csv('/content/drive/MyDrive/SoftCom/training-a.csv')\n",
        "a_csv.columns\n",
        "a_csv = a_csv.drop(columns=['original filename', 'scanid',\n",
        "       'database name original', 'contributing team', 'database name'])\n",
        "a_csv.iloc[:10, 0:]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>digit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>a00000.png</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>a00001.png</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a00002.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>a00003.png</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a00004.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>a00005.png</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>a00006.png</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>a00007.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>a00008.png</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>a00009.png</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     filename  digit\n",
              "0  a00000.png      5\n",
              "1  a00001.png      3\n",
              "2  a00002.png      1\n",
              "3  a00003.png      7\n",
              "4  a00004.png      0\n",
              "5  a00005.png      4\n",
              "6  a00006.png      3\n",
              "7  a00007.png      0\n",
              "8  a00008.png      4\n",
              "9  a00009.png      9"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZexWoX5gyud"
      },
      "source": [
        "label_csv = a_csv"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDFIKv_bg8qc"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(self, df, root, transform=None):\n",
        "        self.data = df\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        item = self.data.iloc[index]\n",
        "        \n",
        "        path = self.root + \"/\" + item[0]\n",
        "        image = Image.open(path).convert('L')\n",
        "        label = item[1]\n",
        "        \n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image)\n",
        "            \n",
        "        return image, label"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r74tkqQzhAAG",
        "outputId": "6d0262e9-8edb-4b50-a567-74cc33e432b5"
      },
      "source": [
        "mean = [0.5,]\n",
        "std = [0.5, ]\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(180),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "        transforms.Resize(180),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean, std)\n",
        "])\n",
        "\n",
        "train_data  = Dataset(label_csv, path, train_transform)\n",
        "test_data = Dataset(label_csv, path, test_transform)\n",
        "\n",
        "print(\"Trainig Samples: \",len(train_data))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainig Samples:  19702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0J611xlhBUV"
      },
      "source": [
        "batch_size = 500\n",
        "num_iters = 60000\n",
        "input_dim = 180*180 \n",
        "num_hidden = 200  \n",
        "output_dim = 10\n",
        "num_epochs = num_iters / (len(train_data) / batch_size)\n",
        "num_epochs = int(num_epochs)\n",
        "learning_rate = 0.01  # More power so we can learn faster! previously it was 0.001\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_data, \n",
        "                                           batch_size=batch_size, \n",
        "                                           shuffle=True)   # It's better to shuffle the whole training dataset! \n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_data, \n",
        "                                          batch_size=batch_size, \n",
        "                                          shuffle=False)  "
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5ciUquAhK89",
        "outputId": "33d24c02-d804-40ee-aea5-f049607c9f47"
      },
      "source": [
        "import torch.nn as nn\n",
        "class DeepNeuralNetworkModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes, num_hidden):\n",
        "        super().__init__()\n",
        "       \n",
        "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
        "        \n",
        "        self.relu_1 = nn.ReLU()\n",
        " \n",
        "        \n",
        "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
        "        \n",
        "        self.relu_2 = nn.ReLU()\n",
        " \n",
        "        \n",
        "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
        "        \n",
        "        self.relu_3 = nn.ReLU()\n",
        " \n",
        "         \n",
        "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
        "        \n",
        "        self.relu_4 = nn.ReLU()\n",
        " \n",
        "         \n",
        "        self.linear_5= nn.Linear(num_hidden, num_hidden)\n",
        "        \n",
        "        self.relu_5= nn.ReLU()\n",
        " \n",
        "         \n",
        "        self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
        "        \n",
        "        self.relu_6 = nn.ReLU()\n",
        " \n",
        "        \n",
        "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
        " \n",
        "    def forward(self, x):\n",
        "        ### 1st hidden layer\n",
        "        out  = self.linear_1(x)\n",
        "        ### Non-linearity in 1st hidden layer\n",
        "        out = self.relu_1(out)\n",
        "        \n",
        "        ### 2nd hidden layer\n",
        "        out  = self.linear_2(out)\n",
        "        ### Non-linearity in 2nd hidden layer\n",
        "        out = self.relu_2(out)\n",
        " \n",
        "        ### 3rd hidden layer\n",
        "        out  = self.linear_3(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_3(out)\n",
        " \n",
        "        out  = self.linear_4(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_4(out)\n",
        " \n",
        "        out  = self.linear_5(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_5(out)\n",
        " \n",
        "        out  = self.linear_6(out)\n",
        "        ### Non-linearity in 3rd hidden layer\n",
        "        out = self.relu_6(out)\n",
        "        \n",
        "        # Linear layer (output)\n",
        "        probas  = self.linear_out(out)\n",
        "        return probas\n",
        " \n",
        "# INSTANTIATE MODEL CLASS\n",
        " \n",
        "model = DeepNeuralNetworkModel(input_size = input_dim,\n",
        "                               num_classes = output_dim,\n",
        "                               num_hidden = num_hidden)\n",
        "# To enable GPU\n",
        "model.to(device)\n",
        " \n",
        "# INSTANTIATE LOSS & OPTIMIZER CLASS\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        " \n",
        "iter = 0\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        " \n",
        "        images = images.view(-1, 180*180).to(device)\n",
        "        labels = labels.to(device)\n",
        " \n",
        "        # Clear gradients w.r.t. parameters\n",
        "        optimizer.zero_grad()\n",
        " \n",
        "        # Forward pass to get output/logits\n",
        "        outputs = model(images) \n",
        " \n",
        "        # Calculate Loss: softmax --> cross entropy loss\n",
        "        loss = criterion(outputs, labels)\n",
        " \n",
        "        # Getting gradients w.r.t. parameters\n",
        "        loss.backward()\n",
        " \n",
        "        # Updating parameters\n",
        "        optimizer.step()\n",
        " \n",
        "        iter += 1\n",
        " \n",
        "        if iter % 500 == 0:\n",
        "            # Calculate Accuracy         \n",
        "            correct = 0\n",
        "            total = 0\n",
        "            # Iterate through test dataset\n",
        "            for images, labels in test_loader:\n",
        "               \n",
        "                images = images.view(-1, 180*180).to(device)\n",
        " \n",
        "                # Forward pass only to get logits/output\n",
        "                outputs = model(images)\n",
        " \n",
        "                # Get predictions from the maximum value\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        " \n",
        "                # Total number of labels\n",
        "                total += labels.size(0)\n",
        " \n",
        " \n",
        "                # Total correct predictions\n",
        "                if torch.cuda.is_available():\n",
        "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
        "                else:\n",
        "                    correct += (predicted == labels).sum()\n",
        " \n",
        "            accuracy = 100 * correct.item() / total\n",
        " \n",
        "            # Print Loss\n",
        "            print('Iteration: {}. \\n Loss: {}.\\n  Accuracy: {}\\n'.format(iter, loss.item(), accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 500. \n",
            " Loss: 2.301699161529541.\n",
            "  Accuracy: 10.02436300883159\n",
            "\n",
            "Iteration: 1000. \n",
            " Loss: 2.3020946979522705.\n",
            "  Accuracy: 10.02436300883159\n",
            "\n",
            "Iteration: 1500. \n",
            " Loss: 2.3013253211975098.\n",
            "  Accuracy: 10.02436300883159\n",
            "\n",
            "Iteration: 2000. \n",
            " Loss: 2.3006746768951416.\n",
            "  Accuracy: 10.02436300883159\n",
            "\n",
            "Iteration: 2500. \n",
            " Loss: 2.2970261573791504.\n",
            "  Accuracy: 10.02436300883159\n",
            "\n",
            "Iteration: 3000. \n",
            " Loss: 2.293267011642456.\n",
            "  Accuracy: 10.02436300883159\n",
            "\n",
            "Iteration: 3500. \n",
            " Loss: 2.2848546504974365.\n",
            "  Accuracy: 10.877068317937265\n",
            "\n",
            "Iteration: 4000. \n",
            " Loss: 2.2114226818084717.\n",
            "  Accuracy: 12.810882143944777\n",
            "\n",
            "Iteration: 4500. \n",
            " Loss: 2.1988112926483154.\n",
            "  Accuracy: 10.501471931783575\n",
            "\n",
            "Iteration: 5000. \n",
            " Loss: 2.1545140743255615.\n",
            "  Accuracy: 11.684092985483707\n",
            "\n",
            "Iteration: 5500. \n",
            " Loss: 2.0532326698303223.\n",
            "  Accuracy: 11.069942137854024\n",
            "\n",
            "Iteration: 6000. \n",
            " Loss: 2.020364284515381.\n",
            "  Accuracy: 10.136026799309715\n",
            "\n",
            "Iteration: 6500. \n",
            " Loss: 1.9380271434783936.\n",
            "  Accuracy: 11.379555375088824\n",
            "\n",
            "Iteration: 7000. \n",
            " Loss: 1.9722332954406738.\n",
            "  Accuracy: 10.115724291950055\n",
            "\n",
            "Iteration: 7500. \n",
            " Loss: 1.8584715127944946.\n",
            "  Accuracy: 12.887016546543498\n",
            "\n",
            "Iteration: 8000. \n",
            " Loss: 1.914551854133606.\n",
            "  Accuracy: 10.04466551619125\n",
            "\n",
            "Iteration: 8500. \n",
            " Loss: 1.8017189502716064.\n",
            "  Accuracy: 11.63333671708456\n",
            "\n",
            "Iteration: 9000. \n",
            " Loss: 1.8332645893096924.\n",
            "  Accuracy: 14.947721043548878\n",
            "\n",
            "Iteration: 9500. \n",
            " Loss: 2.1211280822753906.\n",
            "  Accuracy: 9.740127905796365\n",
            "\n",
            "Iteration: 10000. \n",
            " Loss: 1.7973353862762451.\n",
            "  Accuracy: 12.826109024464522\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "CkaUWvnIhWmc",
        "outputId": "69d784ae-a803-4b2a-f07a-1a2001176c06"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "print (iteration_loss)\n",
        "plt.plot(iteration_loss)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Iteration')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-8fe7b0618926>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miteration_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'iteration_loss' is not defined"
          ]
        }
      ]
    }
  ]
}